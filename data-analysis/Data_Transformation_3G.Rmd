---
title: "Data Exploration"
author: "Madalina Dinga"
date: "10/20/2020"
output:
  pdf_document:
    fig_caption: yes
  word_document: default
highlight: tango
fontsize: 11pt
---


```{r}
#options(digits = 3)
```

Input: _Aggregated_Reps_3G.csv_
Factors (Perfume.js metrics):
1. __headerSize__ - size of the header
2. __timeToFirstByte__ (ms) -  Time to First Byte (TTFB) - The amount of time ittakes for the server to send the first payload to the client
3. __downloadTime__ - Download Time (ms) - Response time only (download)
4. __totalTime__ - Total time (ms) - Request plus response time (network only)
5. __totalLoadTime__ (ms) - The time taken for the entire page to be loaded (the time taken until the onload callback is called)
6.  __fcp__ - First Contentful Paint (ms) - The time from when thepage starts loading to when the first bit of meaningful content is rendered
7. __fp__ - First Paint (ms) - The exact time taken for the browser to render anything as visually different from what was on the screen before navigation
Blocking factor: 
__network conditions__- 3G

Numerical outcome (dependent variable):
__batterystats_Joule_calculated__ - energy efficiency measured with battery stats (Joules)

Read the data:
```{r}
library(tidyverse)

threeG_df = read_csv("../experiment-data/3g/Aggregated_Reps_3G.csv", col_names = TRUE)

#Keep only the relevant columns
keeps <- c("subject","headerSize", "fetchTime", "timeToFirstByte", "downloadTime", "totalTime", "totalLoadTime", "fcp", "fp", "batterystats_Joule_calculated")
threeG_df = threeG_df[keeps]

#Count of rows and columns
dim(threeG_df)
#View top rows of the dataset
head(threeG_df)
```

Aggregate runs for each subject (obtain 1 row per subject)
We first order by subject, then average the measurements from each subject.

```{r}
library(dplyr)
threeG_df_sorted = arrange(threeG_df, subject)

n = dim(threeG_df_sorted)[1]

threeG_df_aggregated = data.frame()
i = 1

while (i<=330){
  j = i + 10
  subj = as.character(unlist(threeG_df_sorted[i,]["subject"]))
  headerSizeAvg = colMeans(slice(threeG_df_sorted, i:j)["headerSize"])
  fetchTimeAvg = colMeans(slice(threeG_df_sorted, i:j)["fetchTime"])
  timeToFirstByteAvg = colMeans(slice(threeG_df_sorted, i:j)["timeToFirstByte"])
  totalTimeAvg = colMeans(slice(threeG_df_sorted, i:j)["totalTime"])
  downloadTimeAvg = colMeans(slice(threeG_df_sorted, i:j)["downloadTime"])
  totalLoadTimeAvg = colMeans(slice(threeG_df_sorted, i:j)["totalLoadTime"])
  fcpAvg = colMeans(slice(threeG_df_sorted, i:j)["fcp"])
  fpAvg = colMeans(slice(threeG_df_sorted, i:j)["fp"])
  batteryStatsAvg = colMeans(slice(threeG_df_sorted, i:j)["batterystats_Joule_calculated"])
  
  i = i+11
  
 avgRun = data.frame(subj, fetchTimeAvg, headerSizeAvg, timeToFirstByteAvg, totalTimeAvg, downloadTimeAvg, totalLoadTimeAvg, fcpAvg, fpAvg, batteryStatsAvg)
  names(avgRun) = c("subject", "fetchTimeAvg", "headerSizeAvg", "timeToFirstByteAvg", "totalTimeAvg", "downloadTimeAvg", "totalLoadTimeAvg", "fcpAvg", "fpAvg", "batteryStatsAvg")  
  threeG_df_aggregated = rbind(threeG_df_aggregated, avgRun)
}

dim(threeG_df_aggregated)
head(threeG_df_aggregated)

```


Normalize the data by scaling the score values to range [0, 1], having observed the minimum and the maximum of the Perfume.js metrics.

```{r}
normalize = function(x){
  return((x-min(x)) /(max(x)-min(x)))
}
```

Use the __normalize__ function to perform min-max normalization on the Perfume.js metrics.

```{r}
headerSizeNormalized = as.vector(unlist(lapply(threeG_df_aggregated['headerSizeAvg'], normalize)))
fetchTimeNormalized = as.vector(unlist(lapply(threeG_df_aggregated['fetchTimeAvg'], normalize)))
timeToFirstByteNormalized = as.vector(unlist(lapply(threeG_df_aggregated['timeToFirstByteAvg'], normalize)))
downloadTimeNormalized = as.vector(unlist(lapply(threeG_df_aggregated['downloadTimeAvg'], normalize)))
totalTimeNormalized = as.vector(unlist(lapply(threeG_df_aggregated['totalTimeAvg'], normalize)))
totalLoadTimeNormalized = as.vector(unlist(lapply(threeG_df_aggregated['totalLoadTimeAvg'], normalize)))
fcpNormalized = as.vector(unlist(lapply(threeG_df_aggregated['fcpAvg'], normalize)))
fpNormalized = as.vector(unlist(lapply(threeG_df_aggregated['fpAvg'], normalize)))
```

Add normalized columns to threeG_df_aggregated
```{r}
dim(threeG_df_aggregated)
threeG_df_aggregated$headerSizeNormalized = headerSizeNormalized
threeG_df_aggregated$fetchTimeNormalized = fetchTimeNormalized
threeG_df_aggregated$timeToFirstByteNormalized = timeToFirstByteNormalized
threeG_df_aggregated$downloadTimeNormalized = downloadTimeNormalized
threeG_df_aggregated$totalTimeNormalized = totalTimeNormalized
threeG_df_aggregated$totalLoadTimeNormalized = totalLoadTimeNormalized
threeG_df_aggregated$fcpNormalized = fcpNormalized
threeG_df_aggregated$fpNormalized = fpNormalized
dim(threeG_df_aggregated)
head(threeG_df_aggregated)
```

Obtain a composed performance score for each of the categories (navigation timing and load speed), by computing an average of the associated metrics.

Consider __headerSize__, __fetchTime__, __timeToFirstByte__, __downloadTime__, __totalTime__ for navigation timing
```{r}
 threeG_df_aggregated$navigationMean <- rowMeans(threeG_df_aggregated[,c('headerSizeNormalized', 'fetchTimeNormalized', 'timeToFirstByteNormalized', 'downloadTimeNormalized', 'totalTimeNormalized')], na.rm=TRUE)
```

Consider __fp__, __fcp__, __totalLoadTime__ for load speed.
```{r}
threeG_df_aggregated$loadMean <- rowMeans(threeG_df_aggregated[,c('fpNormalized', 'fcpNormalized', 'totalLoadTimeNormalized')], na.rm=TRUE)
head(threeG_df_aggregated)
```


In order to simplify the statistical analysis, quantify the scores for each performance category by transforming the ratio measures into ordinal ones. To this end, define three levels for navigation timing/load speed, respectively, using two cutting points. We obtain an equal number of subjects on each level (low,average and high).

Sort __threeG_df__ by average navigation timing __navigationMean__.

```{r}
library(dplyr)
threeG_navigation_df = arrange(threeG_df_aggregated, navigationMean)
head(threeG_navigation_df)
```

Sort __threeG_df__ by load speed average __loadMean__.

```{r}
threeG_load_df = arrange(threeG_df_aggregated, loadMean)
head(threeG_load_df)
```

Append low/average/high performance levels (ordinal measure).

```{r}
performanceLvl <- numeric(30)
for (i in 1:10) {
  performanceLvl[i] <- "low"
}
for (i in 11:20) {
  performanceLvl[i] <- "average"
}
for (i in 21:30) {
  performanceLvl[i] <- "high"
}

# Append new column (performanceLvl) to threeG_navigation_df
threeG_navigation_df = cbind(threeG_navigation_df, data.frame(performanceLvl, stringsAsFactors=FALSE))
# Append new column (performanceLvl) to threeG_load_df
threeG_load_df = cbind(threeG_load_df, data.frame(performanceLvl, stringsAsFactors=FALSE))
```

Clean dfs, only keep relevant columns
```{r}
keeps <- c("subject", "navigationMean","headerSizeAvg", "timeToFirstByteAvg", "fetchTimeAvg", "downloadTimeAvg", "totalTimeAvg", "navigationMean","headerSizeNormalized", "timeToFirstByteNormalized", "fetchTimeNormalized", "downloadTimeNormalized", "totalTimeNormalized", "batteryStatsAvg")
threeG_navigation_df = threeG_navigation_df[keeps]

keeps <- c("subject", "totalLoadTimeAvg", "fcpAvg", "fpAvg", "totalLoadTimeNormalized", "fcpNormalized", "fpNormalized", "loadMean", "batteryStatsAvg")
threeG_load_df = threeG_load_df[keeps]
```

Save transformed data for navigation timing:
```{r}
write.csv(threeG_navigation_df,"NavigationTiming_threeG.csv", row.names = TRUE)
```

Save transformed data for load speed:
```{r}
write.csv(threeG_load_df,"LoadSpeed_threeG.csv", row.names = TRUE)
```

