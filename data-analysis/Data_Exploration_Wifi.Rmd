---
title: "Data Exploration"
author: "Madalina Dinga"
date: "10/20/2020"
output: html_document
---


```{r}
#options(digits = 3)
```

Input: _Aggregated_Reps_Wifi.csv_
Factors (Perfume.js metrics):
1. __headerSize__ - size of the header
2. __fetchTime__ - 
3. __timeToFirstByte__ - The amount of time ittakes for the server to send the first payload to the client
4. __downloadTime__ - Response time only (download)
5. __totalTime__ - Request plus response time (network only)
6. __totalLoadTime__ - 
7. __fcp__ - The time from when thepage starts loading to when the first bit of meaningfulcontent is rendered
8. __fp__ - The exact time taken for the browserto render anything as visually different from what was onthe screen before navigation
Blocking factor: 
__network conditions__- Wifi

Numerical outcome (dependent variable):
__batterystats_Joule_calculated__ - energy efficiency measured with battery stats (Joules)

Read the data:
```{r}
library(tidyverse)

wifi_df = read_csv("../experiment-data/wifi/Aggregated_Reps_Wifi.csv", col_names = TRUE)
attach(wifi_df)

#Keep only the relevant columns
keeps <- c("headerSize", "fetchTime", "timeToFirstByte", "downloadTime", "totalTime", "totalLoadTime", "fcp", "fp", "batterystats_Joule_calculated")
wifi_df = wifi_df[keeps]

#Count of rows and columns
dim(wifi_df)
#View top rows of the dataset
head(wifi_df)
```

Normalize the data by scaling the score values to range [0, 1], having observed the minimum and the maximum of the Perfume.js metrics.

```{r}
normalize = function(x){
  return((x-min(x)) /(max(x)-min(x)))
}
```

Use the __normalize__ function to perform min-max normalization on the Perfume.js metrics.

```{r}
headerSizeNormalized = as.vector(unlist(lapply(wifi_df['headerSize'], normalize)))
fetchTimeNormalized = as.vector(unlist(lapply(wifi_df['fetchTime'], normalize)))
timeToFirstByteNormalized = as.vector(unlist(lapply(wifi_df['timeToFirstByte'], normalize)))
downloadTimeNormalized = as.vector(unlist(lapply(wifi_df['downloadTime'], normalize)))
totalTimeNormalized = as.vector(unlist(lapply(wifi_df['totalTime'], normalize)))
totalLoadTimeNormalized = as.vector(unlist(lapply(wifi_df['totalLoadTime'], normalize)))
fcpNormalized = as.vector(unlist(lapply(wifi_df['fcp'], normalize)))
fpNormalized = as.vector(unlist(lapply(wifi_df['fp'], normalize)))
```

Add normalized columns to wifi_df.
```{r}
dim(wifi_df)
wifi_df$headerSizeNormalized = headerSizeNormalized
wifi_df$fetchTimeNormalized = fetchTimeNormalized
wifi_df$timeToFirstByteNormalized = timeToFirstByteNormalized
wifi_df$downloadTimeNormalized = downloadTimeNormalized
wifi_df$totalTimeNormalized = totalTimeNormalized
wifi_df$totalLoadTimeNormalized = totalLoadTimeNormalized
wifi_df$fcpNormalized = fcpNormalized
wifi_df$fpNormalized = fpNormalized
dim(wifi_df)
head(wifi_df)
```

Obtain a composed performance score for each of the categories (navigation levels and load speed), by computing an average of the associated metrics.

Consider __headerSize__, __fetchTime__, __timeToFirstByte__, __downloadTime__, __totalTime__, __totalLoadTime__ for navigation levels.
```{r}
 wifi_df$navigationMean <- rowMeans(wifi_df[,c('headerSizeNormalized', 'fetchTimeNormalized', 'timeToFirstByteNormalized', 'downloadTimeNormalized', 'totalTimeNormalized', 'totalLoadTimeNormalized')], na.rm=TRUE)
head(wifi_df)
```

Consider __fp__, __fcp__ for load speed.
```{r}
wifi_df$loadMean <- rowMeans(wifi_df[,c('fp', 'fcp')], na.rm=TRUE)
```

##TODO: for every 30 lines, average the scores!!

In order to simplify the statistical analysis, quantify the scores for each performance category by transforming the ratio measures into ordinal ones. To this end, define three levels for navigation timing/load speed, respectively, using two cutting points. We obtain an equal number of subjects on each level (low,average and high).

Sort __wifi_df__ by navigation level average __navigationMean__.

```{r}
library(dplyr)
wifi_navigation_df = arrange(wifi_df, navigationMean)
head(wifi_navigation_df)
```

Sort __wifi_df__ by load speed average __loadMean__.

```{r}
library(dplyr)
wifi_load_df = arrange(wifi_df, loadMean)
head(wifi_load_df)
```

Append low/average/high levels.



