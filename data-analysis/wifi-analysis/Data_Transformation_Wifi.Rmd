---
title: "Data Transformation Wifi"
author: "____________________"
date: "10/20/2020"
output:
  html_document
---


```{r}
options(digits = 3, warn = -1)
```

Input: _Aggregated_Reps_Wifi.csv_

Factors (Perfume.js metrics):

1. __headerSize__ - size of the header

2. __timeToFirstByte__ (ms) -  Time to First Byte (TTFB) - The amount of time ittakes for the server to send the first payload to the client

3. __downloadTime__ - Download Time (ms) - Response time only (download)

4. __totalTime__ - Total time (ms) - Request plus response time (network only)

5. __totalLoadTime__ (ms) - The time taken for the entire page to be loaded (the time taken until the onload callback is called)

6.  __fcp__ - First Contentful Paint (ms) - The time from when the page starts loading to when the first bit of meaningful content is rendered

7. __fp__ - First Paint (ms) - The exact time taken for the browser to render anything as visually different from what was on the screen before navigation

Numerical outcome (dependent variable):

__batterystats_Joule_calculated__ - energy efficiency measured with battery stats (Joules)

Read the data:
```{r}
library(tidyverse)

read_data <- function(file_path) {
  wifi_df = read_csv(file_path, col_names = TRUE)

  #Keep only the relevant columns
  keeps <- c("subject","headerSize", "fetchTime", "timeToFirstByte", "downloadTime", "totalTime", "totalLoadTime", "fcp", "fp", "batterystats_Joule_calculated")
  wifi_df = wifi_df[keeps]
}

wifi_df = read_data("../experiment-data/wifi/Aggregated_Reps_Wifi_cor.csv")
#Count of rows and columns
dim(wifi_df)
#View top rows of the dataset
View(wifi_df)
```

Aggregate runs for each subject (obtain 1 row per subject)
We first order by subject, then average the measurements from each subject.

```{r}
library(dplyr)
wifi_df_sorted = arrange(wifi_df, subject)

n = dim(wifi_df_sorted)[1]

wifi_df_aggregated = data.frame()
i = 1

while (i<=330){
  j = i + 10
  subj = as.character(unlist(wifi_df_sorted[i,]["subject"]))
  headerSizeAvg = colMeans(slice(wifi_df_sorted, i:j)["headerSize"])
  fetchTimeAvg = colMeans(slice(wifi_df_sorted, i:j)["fetchTime"])
  timeToFirstByteAvg = colMeans(slice(wifi_df_sorted, i:j)["timeToFirstByte"])
  totalTimeAvg = colMeans(slice(wifi_df_sorted, i:j)["totalTime"])
  downloadTimeAvg = colMeans(slice(wifi_df_sorted, i:j)["downloadTime"])
  totalLoadTimeAvg = colMeans(slice(wifi_df_sorted, i:j)["totalLoadTime"])
  fcpAvg = colMeans(slice(wifi_df_sorted, i:j)["fcp"])
  fpAvg = colMeans(slice(wifi_df_sorted, i:j)["fp"])
  batteryStatsAvg = colMeans(slice(wifi_df_sorted, i:j)["batterystats_Joule_calculated"])
  
  i = i+11
  
  avgRun = data.frame(subj, fetchTimeAvg, headerSizeAvg, timeToFirstByteAvg, totalTimeAvg, downloadTimeAvg, totalLoadTimeAvg, fcpAvg, fpAvg, batteryStatsAvg)
  names(avgRun) = c("subject", "fetchTimeAvg", "headerSizeAvg", "timeToFirstByteAvg", "totalTimeAvg", "downloadTimeAvg", "totalLoadTimeAvg", "fcpAvg", "fpAvg", "batteryStatsAvg")  
  wifi_df_aggregated = rbind(wifi_df_aggregated, avgRun)
}

dim(wifi_df_aggregated)
```


Normalize the data by scaling the score values to range [0, 1], having observed the minimum and the maximum of the Perfume.js metrics.

```{r}
normalize = function(x){
  return((x-min(x)) /(max(x)-min(x)))
}
```

Use the __normalize__ function to perform min-max normalization on the Perfume.js metrics.

```{r}
headerSizeNormalized = as.vector(unlist(lapply(wifi_df_aggregated['headerSizeAvg'], normalize)))
fetchTimeNormalized = as.vector(unlist(lapply(wifi_df_aggregated['fetchTimeAvg'], normalize)))
timeToFirstByteNormalized = as.vector(unlist(lapply(wifi_df_aggregated['timeToFirstByteAvg'], normalize)))
downloadTimeNormalized = as.vector(unlist(lapply(wifi_df_aggregated['downloadTimeAvg'], normalize)))
totalTimeNormalized = as.vector(unlist(lapply(wifi_df_aggregated['totalTimeAvg'], normalize)))
totalLoadTimeNormalized = as.vector(unlist(lapply(wifi_df_aggregated['totalLoadTimeAvg'], normalize)))
fcpNormalized = as.vector(unlist(lapply(wifi_df_aggregated['fcpAvg'], normalize)))
fpNormalized = as.vector(unlist(lapply(wifi_df_aggregated['fpAvg'], normalize)))
```

Add normalized columns to wifi_df_aggregated
```{r}
wifi_df_aggregated$headerSizeNormalized = headerSizeNormalized
wifi_df_aggregated$fetchTimeNormalized = fetchTimeNormalized
wifi_df_aggregated$timeToFirstByteNormalized = timeToFirstByteNormalized
wifi_df_aggregated$downloadTimeNormalized = downloadTimeNormalized
wifi_df_aggregated$totalTimeNormalized = totalTimeNormalized
wifi_df_aggregated$totalLoadTimeNormalized = totalLoadTimeNormalized
wifi_df_aggregated$fcpNormalized = fcpNormalized
wifi_df_aggregated$fpNormalized = fpNormalized
dim(wifi_df_aggregated)
```

Obtain a composed performance score for each of the categories (navigation timing and load speed), by computing an average of the associated metrics.

Consider __headerSize__, __fetchTime__, __timeToFirstByte__, __downloadTime__, __totalTime__ for navigation timing
```{r}
 wifi_df_aggregated$navigationMean <- rowMeans(wifi_df_aggregated[,c('headerSizeNormalized', 'fetchTimeNormalized', 'timeToFirstByteNormalized', 'downloadTimeNormalized', 'totalTimeNormalized')], na.rm=TRUE)
```

Consider __fp__, __fcp__, __totalLoadTime__ for load speed.
```{r}
wifi_df_aggregated$loadMean <- rowMeans(wifi_df_aggregated[,c('fpNormalized', 'fcpNormalized', 'totalLoadTimeNormalized')], na.rm=TRUE)
```


In order to simplify the statistical analysis, quantify the scores for each performance category by transforming the ratio measures into ordinal ones. To this end, define three levels for navigation timing/load speed, respectively, using two cutting points. We obtain an equal number of subjects on each level (low,average and high).

Sort __wifi_df__ by average navigation timing __navigationMean__.

```{r}
library(dplyr)
wifi_navigation_df = arrange(wifi_df_aggregated, navigationMean)
```

Sort __wifi_df__ by load speed average __loadMean__.

```{r}
wifi_load_df = arrange(wifi_df_aggregated, loadMean)
```

Append low/average/high performance levels (ordinal measure).

```{r}
performanceLvl <- numeric(30)
for (i in 1:10) {
  performanceLvl[i] <- "low"
}
for (i in 11:20) {
  performanceLvl[i] <- "average"
}
for (i in 21:30) {
  performanceLvl[i] <- "high"
}

# Append new column (performanceLvl) to wifi_navigation_df
wifi_navigation_df = cbind(wifi_navigation_df, data.frame(performanceLvl, stringsAsFactors=FALSE))
# Append new column (performanceLvl) to wifi_load_df
wifi_load_df = cbind(wifi_load_df, data.frame(performanceLvl, stringsAsFactors=FALSE))
```

Clean dfs, only keep relevant columns
```{r}
keeps <- c("subject", "navigationMean","headerSizeAvg", "timeToFirstByteAvg", "fetchTimeAvg", "downloadTimeAvg", "totalTimeAvg", "navigationMean","headerSizeNormalized", "timeToFirstByteNormalized", "fetchTimeNormalized", "downloadTimeNormalized", "totalTimeNormalized", "batteryStatsAvg", "performanceLvl")
wifi_navigation_df = wifi_navigation_df[keeps]

keeps <- c("subject", "totalLoadTimeAvg", "fcpAvg", "fpAvg", "totalLoadTimeNormalized", "fcpNormalized", "fpNormalized", "loadMean", "batteryStatsAvg", "performanceLvl")
wifi_load_df = wifi_load_df[keeps]
```

Create new __website__ column with shortened names.
```{r}
shorten_webpage_name <- function(fullName){
  name <- strsplit(as.character(fullName), '[-]')
  shortName <- paste(name[[1]][8], name[[1]][9], name[[1]][10], sep=".")
  return(shortName)
}

for (i in 1:length(wifi_navigation_df$subject)) {
  subject = wifi_navigation_df$subject[i]
  wifi_navigation_df$website[i] = shorten_webpage_name(subject)
  wifi_load_df$website[i] = shorten_webpage_name(subject)
}
```

Save transformed data for navigation timing:
```{r}
write.csv(wifi_navigation_df,"NavigationTiming_Wifi.csv", row.names = TRUE)
```

Save transformed data for load speed:
```{r}
write.csv(wifi_load_df,"LoadSpeed_Wifi.csv", row.names = TRUE)
```



